{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz \n",
    "import chromadb\n",
    "import numpy as np\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_FILE = \"ICC_handbook.pdf\"  \n",
    "DB_PATH = \"./chroma_db\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=DB_PATH)\n",
    "collection = chroma_client.get_or_create_collection(name=\"legal_texts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from PDF and returns as a single string.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, chunk_size=500, chunk_overlap=100):\n",
    "    \"\"\"Splits text into chunks for embedding.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMBEDDINGS IN CHROMADB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embeddings(chunks):\n",
    "    \"\"\"Generates and stores embeddings in ChromaDB.\"\"\"\n",
    "    embeddings = model.encode(chunks, show_progress_bar=True)\n",
    "    for i, text in enumerate(chunks):\n",
    "        collection.add(\n",
    "            ids=[str(i)], documents=[text], embeddings=[embeddings[i].tolist()]\n",
    "        )\n",
    "    print(\"Embeddings stored successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chroma(user_input, top_k=3):\n",
    "    \"\"\"Queries ChromaDB for the closest legal text based on user input.\"\"\"\n",
    "    query_embedding = model.encode(user_input).tolist()\n",
    "    results = collection.query(query_embeddings=[query_embedding], n_results=top_k)\n",
    "    return results[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DB_PATH) or not collection.count():\n",
    "    print(\"Database not found! Extracting and storing embeddings...\")\n",
    "    pdf_text = extract_text_from_pdf(PDF_FILE)\n",
    "    text_chunks = split_text(pdf_text)\n",
    "    store_embeddings(text_chunks)\n",
    "else:\n",
    "    print(\"ChromaDB already has embeddings. Ready to query.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD TKINTER GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_legal_text():\n",
    "    \"\"\"Handles the search button click and updates the result box.\"\"\"\n",
    "    user_query = entry.get()\n",
    "    results = query_chroma(user_query)\n",
    "    \n",
    "    output_box.config(state=tk.NORMAL)  # Enable editing\n",
    "    output_box.delete(1.0, tk.END)  # Clear previous output\n",
    "    if results:\n",
    "        output_box.insert(tk.END, \"Top Relevant Sections:\\n\\n\")\n",
    "        for i, result in enumerate(results):\n",
    "            output_box.insert(tk.END, f\"{i+1}. {result}\\n\\n{'='*50}\\n\\n\")\n",
    "    else:\n",
    "        output_box.insert(tk.END, \"No relevant legal text found.\")\n",
    "    output_box.config(state=tk.DISABLED)  # Disable editing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tkinter GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Legal Text Classifier\")\n",
    "root.geometry(\"700x500\")\n",
    "\n",
    "label = tk.Label(root, text=\"Enter Legal Query:\", font=(\"Arial\", 12))\n",
    "label.pack(pady=5)\n",
    "\n",
    "entry = tk.Entry(root, width=60, font=(\"Arial\", 12))\n",
    "entry.pack(pady=5)\n",
    "\n",
    "search_button = tk.Button(root, text=\"Search\", command=search_legal_text, font=(\"Arial\", 12))\n",
    "search_button.pack(pady=5)\n",
    "\n",
    "output_box = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=80, height=20, font=(\"Arial\", 10))\n",
    "output_box.pack(pady=5)\n",
    "output_box.config(state=tk.DISABLED)  # Make it read-only\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
